{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with Amazon Forecast\n",
    "\n",
    "Now we are going to use the previous data set to train a model with Amazon Forecast.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "import subprocess\n",
    "\n",
    "session = boto3.Session(region_name='us-east-1') # Check supported regions\n",
    "\n",
    "forecast = session.client(service_name='forecast')\n",
    "forecastquery = session.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RecipeNames': ['forecast_ARIMA',\n",
       "  'forecast_DEEP_AR',\n",
       "  'forecast_DEEP_AR_PLUS',\n",
       "  'forecast_ETS',\n",
       "  'forecast_MDN',\n",
       "  'forecast_MQRNN',\n",
       "  'forecast_NPTS',\n",
       "  'forecast_PROPHET',\n",
       "  'forecast_SQF'],\n",
       " 'ResponseMetadata': {'RequestId': '3fbdf62a-6048-4c1f-be9f-6cfb0618236b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Wed, 30 Jan 2019 15:07:31 GMT',\n",
       "   'x-amzn-requestid': '3fbdf62a-6048-4c1f-be9f-6cfb0618236b',\n",
       "   'content-length': '174',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check available algorithms\n",
    "forecast.list_recipes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train/Test split\n",
    "\n",
    "To be able to evaluate the forecast quality later, we are going to leave out the last 15 days of data from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96995</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96995</td>\n",
       "      <td>2013-03-31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96995</td>\n",
       "      <td>2013-04-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0           1    2\n",
       "0  96995  2013-02-04  1.0\n",
       "1  96995  2013-03-31  1.0\n",
       "2  96995  2013-04-06  1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"target_time_series.csv\", dtype = object,header=None)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1] = pd.to_datetime(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[1]<'2017-08-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('target_time_series_train.csv',index=None,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = session.client('s3')\n",
    "\n",
    "accountId = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "bucketName = 'amazon-forecast-chrisking-data-mg'# Update to your bucket name\n",
    "key=\"favorita/target_time_series_train.csv\"\n",
    "\n",
    "#s3.upload_file(Filename=\"target_time_series_train.csv\", Bucket=bucketName, Key=key)\n",
    "\n",
    "roleArn = 'arn:aws:iam::%s:role/amazonforecast'%accountId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Dataset\n",
    "\n",
    "Now we are going to create the data set schema in Amazon Forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FREQUENCY = \"D\" \n",
    "TIMESTAMP_FORMAT = \"yyyy-MM-dd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'favorita_forecast2' # Replace this with a unique name here, make sure the entire name is < 30 characters.\n",
    "datasetName= project+'_ds2'\n",
    "datasetGroupName= project +'_gp2'\n",
    "s3DataPath = \"s3://\"+bucketName+\"/\"+key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the schema of your dataset here. Make sure the order of columns matches the raw data files.\n",
    "schema ={\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"demand\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      }\n",
    "   ]\n",
    "}\n",
    "\n",
    "response=forecast.create_dataset(\n",
    "                    Domain=\"RETAIL\",\n",
    "                    DatasetType='TARGET_TIME_SERIES',\n",
    "                    DataFormat='CSV',\n",
    "                    DatasetName=datasetName,\n",
    "                    DataFrequency=DATASET_FREQUENCY, \n",
    "                    TimeStampFormat=TIMESTAMP_FORMAT,\n",
    "                    Schema = schema\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.create_dataset_group(DatasetGroupName=datasetGroupName,RoleArn=roleArn,DatasetNames=[datasetName])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create Data Import Job\n",
    "Brings the data into Amazon Forecast system ready to forecast from raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_import_job_response=forecast.create_dataset_import_job(DatasetName=datasetName,Delimiter=',', DatasetGroupName =datasetGroupName ,S3Uri= s3DataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_versionId=ds_import_job_response['VersionId']\n",
    "print(ds_versionId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    dataImportStatus = forecast.describe_dataset_import_job(DatasetName=datasetName,VersionId=ds_versionId)['Status']\n",
    "    print(dataImportStatus)\n",
    "    if dataImportStatus != 'ACTIVE' and dataImportStatus != 'FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create Solution with your own forecast horizon\n",
    "\n",
    "We are going to use a forecast horizon of 30 days. Even though we are going to evaluate predictions on the 15 days we left out of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorName= project+'_mqrnn2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastHorizon = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.list_recipes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createPredictorResponse=forecast.create_predictor(RecipeName='forecast_MQRNN',DatasetGroupName= datasetGroupName ,PredictorName=predictorName, \n",
    "  ForecastHorizon = forecastHorizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorVerionId=createPredictorResponse['VersionId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    predictorStatus = forecast.describe_predictor(PredictorName=predictorName,VersionId=predictorVerionId)['Status']\n",
    "    print(predictorStatus)\n",
    "    if predictorStatus != 'ACTIVE' and predictorStatus != 'FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.describe_predictor(PredictorName=predictorName,VersionId=predictorVerionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Get Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'favorita_forecast2' # Replace this with a unique name here, make sure the entire name is < 30 characters.\n",
    "predictorName= project+'_mqrnn2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelMetrics': {'MQRNN': {'Metrics': {'p10': '0.19168282136436146',\n",
       "    'p50': '0.6720288740197131',\n",
       "    'p90': '0.4864501466871068',\n",
       "    'rmse': '5.0690687430412815'},\n",
       "   'MetricsByBucket': []}},\n",
       " 'ResponseMetadata': {'RequestId': '4c91609e-a68a-4a27-96c5-69e13d6e7c24',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Wed, 30 Jan 2019 15:47:10 GMT',\n",
       "   'x-amzn-requestid': '4c91609e-a68a-4a27-96c5-69e13d6e7c24',\n",
       "   'content-length': '171',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastquery.get_accuracy_metrics(PredictorName=predictorName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Deploy Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.deploy_predictor(PredictorName=predictorName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployedPredictorsResponse=forecast.list_deployed_predictors()\n",
    "print(deployedPredictorsResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    deployedPredictorStatus = forecast.describe_deployed_predictor(PredictorName=predictorName)['Status']\n",
    "    print(deployedPredictorStatus)\n",
    "    if deployedPredictorStatus != 'ACTIVE' and deployedPredictorStatus != 'FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break\n",
    "print(deployedPredictorStatus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
